\documentclass[english,11pt,letterpaper,onecolumn]{scrartcl}

%\usepackage[utf8]{inputenc}
\usepackage{babel}
\usepackage{csquotes}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathptmx}
\usepackage{enumitem}
% Extra leading.
\renewcommand{\baselinestretch}{1.125}
\usepackage{tocloft}
% \usepackage{fancyhdr}
\usepackage{scrlayer-scrpage}
\usepackage{ifthen}
\usepackage{keyval}
\usepackage{geometry}
\usepackage{url}
\usepackage{calc}
\usepackage{array}
\usepackage{graphicx}
\usepackage{color}
\usepackage{listings}
\usepackage{supertabular}
\usepackage{kbordermatrix}
% definitions used by included articles, reproduced here for
% educational benefit, and to minimize alterations needed to be made
% in developing this sample file.
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amscd}     % commutative diagrams
\usepackage{mathrsfs}  % This package allows the use of script letters. Type \mathscr to invoke math script.
\usepackage{amsbsy}
\newcommand\scalemath[2]{\scalebox{#1}{\mbox{\ensuremath{\displaystyle #2}}}}
%\usepackage{scrpage2}
\usepackage[pdftex,
colorlinks=true,
linkcolor=blue,
pdfpagelabels,
pdfstartpage=3
]{hyperref}
% \usepackage{poemscol}
% \global\verselinenumbersfalse
\makeindex
\definecolor{LstColor}{cmyk}{0.1,0.1,0,0.025}
\setcounter{tocdepth}{9}
\newcommand\floor[1]{\lfloor#1\rfloor}
\newcommand\ceil[1]{\lceil#1\rceil}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\hypersetup{breaklinks=true,
bookmarks=true,
pdfauthor={},
pdftitle={},
colorlinks=true,
citecolor=blue,
urlcolor=blue,
linkcolor=magenta,
pdfborder={0 0 0}}

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}

\usepackage{version}%
\setcounter{MaxMatrixCols}{30}

%%%% Packages added - Peter
\usepackage{color}
\usepackage{amscd}     % commutative diagrams
\usepackage{mathrsfs}  % This package allows the use of script letters.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newtheorem{theorem}{Theorem}[section]
%\theoremstyle{plain}
\newtheorem{acknowledgement}{Acknowledgement}
\newtheorem{algorithm}{Algorithm}[section]
\newtheorem{axiom}{Axiom}[section]
\newtheorem{case}{Case}[section]
\newtheorem{claim}{Claim}[section]
\newtheorem{conclusion}{Conclusion}[section]
\newtheorem{condition}{Condition}[section]
\newtheorem{conjecture}{Conjecture}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{criterion}{Criterion}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]
\newtheorem{exercise}{Exercise}[section]
\newtheorem{lemma}{Lemma}[section]
\newtheorem{notation}{Notation}[section]
\newtheorem{problem}{Problem}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{remark}{Remark}[section]
\newtheorem{solution}{Solution}[section]
\newtheorem{summary}{Summary}[section]
\numberwithin{equation}{section}
\excludeversion{comment1}

%%%%% Macros added - Peter
\newcommand{\st}{\,|\,}
\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\I}{\mathbb{I}}
\newcommand{\bH}{\mathbb{H}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\T}{\mathbb{T}}
\newcommand{\X}{\mathbb{X}}
\newcommand{\Y}{\mathbb{Y}}
\newcommand{\Z}{\mathbb{Z}}
%
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\mcD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\calH}{\mathcal{H}}
\newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\mcL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\calR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\mcT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\cY}{\mathcal{Y}}
\newcommand{\bcF}{\boldsymbol{\mathcal{F}}}
%
\newcommand{\oY}{\overline{Y}}
\newcommand{\uY}{\underline{Y}}
%
\renewcommand{\Re}{\mathop{\mathrm{Re}}}
\renewcommand{\Im}{\mathop{\mathrm{Im}}}
%
\newcommand{\card}{\mathop{\mathrm{card}}}
\newcommand{\Int}{\mathop{\mathrm{int}}}
\newcommand{\eps}{\varepsilon}
\newcommand{\kap}{\varkappa}
\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}
\newcommand{\inn}[2]{{\langle #1,#2 \rangle}}
\newcommand{\wt}[1]{{\widetilde{#1}}}

\newcommand{\conv}{\mathrm{conv}\,}
\newcommand{\bx}{{\boldsymbol{x}}}
\newcommand{\by}{{\boldsymbol{y}}}
\newcommand{\bk}{{\boldsymbol{k}}}
\newcommand{\bm}{{\boldsymbol{m}}}
\newcommand{\bc}{{\boldsymbol{c}}}
\newcommand{\ba}{{\boldsymbol{a}}}
\newcommand{\bp}{{\boldsymbol{p}}}
\newcommand{\bP}{{\mathbb{P}}}
\newcommand{\bS}{{\boldsymbol{S}}}
\newcommand{\bq}{{\boldsymbol{q}}}
\newcommand{\bfe}{{\boldsymbol{e}}}
\newcommand{\bone}{{\boldsymbol{1}}}
\newcommand{\bu}{{\boldsymbol{u}}}
\newcommand{\bv}{{\boldsymbol{v}}}
\newcommand{\bw}{{\boldsymbol{w}}}
\newcommand{\bff}{{\boldsymbol{f}}}
\newcommand{\bkk}{{\boldsymbol{k-1}}}
\newcommand{\bxi}{{\boldsymbol{Xi}}}
\newcommand{\balpha}{{\boldsymbol{\alpha}}}
\newcommand{\bbeta}{{\boldsymbol{\beta}}}
\newcommand{\bgamma}{{\boldsymbol{\gamma}}}
\newcommand{\blambda}{{\boldsymbol{\lambda}}}
\newcommand{\bmu}{{\boldsymbol{\mu}}}
\newcommand{\gr}{{\mathrm{graph\,}}}
\newcommand{\of}{\overline{f}}
\newcommand{\og}{\overline{g}}
\newcommand{\oc}{\overline{c}}
\newcommand{\ou}{\overline{u}}
\newcommand{\ox}{\overline{x}}
\newcommand{\oX}{\overline{X}}
\newcommand{\oXi}{\overline{X}_i}
\newcommand{\uc}{\underline{c}}
\newcommand{\oy}{\overline{y}}
\newcommand{\uy}{\underline{y}}
\newcommand{\odelta}{\overline{\delta}}
\newcommand{\udelta}{\underline{\delta}}
\newcommand{\oPhi}{\overline{\Phi}}
\newcommand{\map}{\textrm{Map}\,}
\newcommand{\loc}{\mathrm{loc}}
\newcommand{\mydot}{\;\cdot\;}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\range}{range}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\Aff}{Aff}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\diag}{diag}

\usepackage[
backend=biber,
bibencoding=utf8,
style=numeric,
sorting=ynt,
hyperref=true,
backref=true
]{biblatex}
\addbibresource{gogins.bib}
\begin{document}

\title{Bottom Up and Top Down} \author{Michael
Gogins \\ \texttt{michael.gogins@gmail.com}} \maketitle
%\pagestyle{scrheadings}

Recently I have completed some projects that, in combination, give me significantly deeper insight into the fundamental potential of algorithmic composition. 

\begin{itemize}
	\item I have finally managed to formalize and implement my intuition of a universal method of parametric composition based on fractal functions in score space, in my own algorithmic composition system Silencio. 
	
	\item I have implemented foreign function interfaces to Csound for existing algorithmic composition systems in Common Lisp (Common Music, OpenMusic, Drew Krause's code, and Slippery Chicken) and Haskell (Haskell School of Music, Euterpea, Kulitta, and Jazzkell). 
	
	\item Inspired by the music of Drew Krause and Donya Quick, I have composed some studies of my own along lines similar to theirs.
\end{itemize}

Before going further, I state here my hypothesis that algorithmic composition is of interest to composers \textit{only} because of what mathematicians call computational irreducibility: the well known fact that what most algorithms do cannot be predicted by reading them. You have to \textit{run} them in order to understand what they do. Paradoxically, although it is obvious if you think about it, this is necessary if the algorithm is to augment or amplify the imagination of the composer.

There are many, indeed there are \textit{too many}, algorithmic composition systems, most of which have not been used by anyone other than their authors (or their authors' students). However, at the risk of over-simplifying, each of these systems falls into one of a few general categories. In the order of their invention:

\begin{description}
	\item[Bottom-up, or accretive.] The system contains a toolkit for generating and transforming musical materials. The tools in the kit are like the things composers already know how to do: generate a random process, sample from a collection, generate a harmony to accompany a melody by following textbook rules (or composer-specified rules), generate a counterpoint to accompany a cantus by following textbook rules (or composer-specified rules), vary or chop up materials, and so on. Irreducibility enters in by the algorithms performing so many steps that their results cannot be predicted in advance, from randomness, and from non-linearity. The original research in algorithmic composition published in \textit{\textbf{Experimental Music}} is of this type, as are Common Music and its descendants.
	
	\item[Top-down, or fractal.] The system generates a fractal by applying a single transformation, such as an iterated function system, to some musical materials. This transformation, necessarily contractive, brings the materials to a fixed point or attractor, which is the piece. In reality, in order to map the generated fractal to a musical score, either the algorithm must stop short of infinity, or a finite set of notes must be sampled from the attractor. Irreducibility enters in at the global level, from the non-linearity of the algorithm's generating kernel. I would say that methods of composition that map natural processes, images, and so on to music are also of this top-down type. Pieces such as \textit{\textbf{Viola Elegy}} are of this type, and I would include some pieces by John Cage in this category. Various fractal generating algorithms have been incorporated in the bottom-up systems.
	
	\item[Imitative, or machine learning.] The system uses pattern matching or statistics to learn how to compose the kind of music that the composer likes, based on a corpus. The composer, or somebody, has to train the system by providing feedback regarding the value of pieces that are generated. Irreducibility enters in with the nonlinear mathematics of the neural networks used for learning. The machine learning approach to composition is still new.
\end{description}

I have developed new insight out of my struggle with the bottom-up approach, as well from as my attempts to bring some of the textbook into the top-down approach, by making harmony and counterpoint into virtual dimensions of the space in which fractals are generated. What I have learned may be peculiar to myself, and may reflect my lack of training, experience, or even talent with conventional methods of composition. Nevertheless, it seems to me that by locating the computational irreducibility at the top or global level, the end results can be both more original and more formally unified. I have also come to see that minor differences in, for example, the type of iterated function system used can have a big impact on the variety of forms that can be generated. Here is my take on the pros and cons of the top-down and bottom-up methods:

\begin{description}
	\item[Top-Down] Or fractal.
	\begin{description}
		\item[Pros] Originality (i.e. not an imitation of past styles), formal unity.
		\item[Cons] Difficulty of control, difficulty of editing out bad passages, difficulty of composing large-scale changes of texture or form.
	\end{description}
	\item[Bottom-Up] Or recipe-based.
	\begin{description}
		\item[Pros] Ease of control, ease of editing out bad passages, ease of composing large-scale contrasts of texture or form.
		\item[Cons] Tends to imitate styles of the past (usually, \textit{i.e.}, classical modernism), pastiche, even kitsch.
	\end{description}
\end{description}

At least for me personally, the top-down approach is more productive. And the path towards improving it seems to be clear. The global contractivity should be retained as providing a global, unified control of computational irreducibility, while every effort should be made to generalize the behavior of the generative kernel. 

To clarify my remarks, consider that iterated function systems (also known as the multiple copy reducing machine algorithm) provide a template for understanding many different kinds of fractal-generating systems. Such an IFS consists of a Hutchinson operator, which is a finite set of affine transformations. The Hutchinson operator is contractive on the whole, so that when it is iterated starting with any arbitrary set having the same dimension as the transformations, by the Brouwer Fixed Point Theorem the system comes to a fixed point, or attractor, which typically is a fractal. The mathematics is quite simple. Over the years Barnsley and others have introduced variant forms of IFS such as recurrent IFS, local IFS, fractels, and so on. These tend to make it easier to compose pieces with large-scale contrasts of texture or form. Essentially, instead of the IFS consisting of a Hutchinson operator that is a simple list of affine transformations, the operator is equipped with additional structure such as a recurrence matrix, a finite state machine, or a set of characteristic functions.

Although the top-down and bottom-up methods might seem to be mathematically distinct, it is very important to understand that it is, in fact, possible to establish an equivalence between them, as set forth in Section 8.2 of Prusinkiewicz and Lindenmayer's \textit{\textbf{The Algorithmic Beauty of Plants}}. A Lindenmayer system is a string rewriting grammar that is very much an example of a bottom-up system. However, by specifying certain constraints on the actions of a parametric Lindenmayer system and then iterating it to infinity, it is possible to compute the same set that an iterated function system computes. In fact, such a Lindenmayer system becomes an implementation of the deterministic algorithm for computing an IFS. But of course, under these constraints, the Lindenmayer system changes character and becomes a top-down system. And this is due to contractivity within the rules that replace line segments with line segments. This should make us realize that the essential difference is between accretion and refinement. Traditional composition, whether by hand or by aid of computers, is accretive. What I am learning is that I should stick with my refinement approach but make it more flexible.

This of course raises some interesting and perhaps important questions for myself. Do I need both Lindenmayer systems and iterated function systems, or can I use just one? If so, how can I modify it to be more general? Can I stick accretive algorithms inside my refinement algorithm?






\printbibliography
\end{document}
